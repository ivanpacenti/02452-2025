{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c05e2ea",
   "metadata": {},
   "source": [
    "**02452** *Machine Learning*, Technical University of Denmark\n",
    "\n",
    "- This Jupyter notebook contains exercises where you fill in missing code related to the lecture topic. *First*, try solving each task yourself. *Then* use the provided solution (an HTML file you can open in any web browser) as inspiration if needed. If you get stuck, ask a TA for help.\n",
    "\n",
    "- Some tasks may be difficult or time-consuming - using the solution file or TA support is expected and perfectly fine, as long as you stay active and reflect on the solution.\n",
    "\n",
    "- You are not expected to finish everything during the session. Prepare by looking at the exercises *before* the class, consult the TAs *during* class, and complete the remaining parts *at home*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239ddc52",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f9e54c",
   "metadata": {},
   "source": [
    "# Week 2: Summary statistics, similarity, Nearest Neighbors and Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b727381",
   "metadata": {},
   "source": [
    "**Content:**\n",
    "- Part 1: Summary statistics and measures of similarity\n",
    "- Part 2: Nearest neighbors method in Python\n",
    "- Part 3: Decision trees in Python\n",
    "- Part 4: Classifying vertebrates with nearest neighbors and decision trees\n",
    "- Part 5: Supervised learning on the Wine data\n",
    "\n",
    "**Objectives:**\n",
    "- Understand how to calculate summary statistics such as mean, variance, median, range, covariance and correlation.\n",
    "- Understand the various measures of similarity such as Jaccard and Cosine similarity and apply similarity measures to query for similar observations.\n",
    "- Become familiar with fitting decision trees and $k$-nearest neighbor models in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51312853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_theme(font_scale=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758878e5",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this exercise, we start by taking a closer look on some of the building blocks of machine learning and statistical modeling, namely **summary statistics** and **similarity measures**. While summary statistics capture key properties of data and help us understand and compare datasets, similarity metrics such as cosine similarity and norm-based distances are essential for certain machine learning methods, e.g. **$k$-nearest neighbors (kNN)** and **decision trees (DCTs)**. In the final parts of the exercise, we will do **supervised learning** with kNNs and DCTs on two real datasets.\n",
    "\n",
    "We first recap a few basic summary statistics and make sure you are comfortable computing these by hand and in Python. You may need to look up the definitions in the lecture notes.\n",
    "\n",
    "**Task I.1:** Using pen and paper and a **basic** electronic calculator (e.g. on your computer), calculate the (empirical) mean, standard deviation (unbiased), median, and range of the following collection of numbers:\n",
    "> $\\mathbf{x}=[-0.68, -2.11,  2.39,  0.26,  1.46,  1.33,  1.03, -0.41, -0.33, 0.47]$\n",
    "\n",
    "**Task I.2:** Verify your results by computing the same quantities with Python.\n",
    "> *Hint:* Look at the help page of the functions `np.mean()`, `np.std()`, `np.median()`, `np.min()` and `np.max()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76aef2f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9700f922fad32c2df32f2d392f0903a3",
     "grade": false,
     "grade_id": "cell-c8550f2b75920985",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([-0.68, -2.11, 2.39, 0.26, 1.46, 1.33, 1.03, -0.41, -0.33, 0.47])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea8df5",
   "metadata": {},
   "source": [
    "**Task I.3:** Compute both the unbiased and biased estimate of the standard deviation using `np.std()`. Are the two estimates the same? What is the difference?\n",
    "> *Hint:* Consider what the argument `ddof=1` means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec23a62",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbdf44d59edf4e366b78b17826687f21",
     "grade": false,
     "grade_id": "cell-71619e9b03928965",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21ed83b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part 1: Using similarity measures to retrieve information\n",
    "\n",
    "We will take a closer look at **similarity measures** and how they form the basis of information retrieval systems. Specifically, we examine how to extract the most similar items from a **database** given a **query** - a central mechanism in **recommender systems** that is used in everything from movie suggestions on Netflix to improved response generation in large language models (LLMs) such as ChatGPT. \n",
    "\n",
    "Specifically, we have a dataset of $N=9298$ handwritten digits (USPS handwritten digits database), transformed to images of size $M=16\\times 16 = 256$ pixels. We store the flattened images in a matrix as \n",
    "$$\n",
    "    \\boldsymbol{X} = \\begin{bmatrix} \\boldsymbol{x}_1 \\\\ \\boldsymbol{x}_2 \\\\ \\vdots \\\\ \\boldsymbol{x}_N \\end{bmatrix} = \\underbrace{ \\begin{bmatrix} x_{1,1} & x_{1,2} & \\cdots & x_{1,256} \\\\ x_{2,1} & x_{2,2} & \\cdots & x_{2,256} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{N,1} & x_{N,2} & \\cdots & x_{N,256} \\end{bmatrix}}_{M}\n",
    "$$\n",
    "Hence, each attribute corresponds to a particular pixel in the image where its value defines the grayscale intensity of the pixel. The goal is to match a **query image**, $\\boldsymbol{q}$, to the images in the database $\\boldsymbol{X}$, and extract the most similar one(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23bb102",
   "metadata": {},
   "source": [
    "**Task 1.4:** Check the associated data folder. Load the `digits.npy` file and plot the first 5 samples in a subplot.\n",
    "\n",
    "> *Hint:* You can load `.npy`-files using `np.load()`.\n",
    "\n",
    "> *Hint:* Remember that you can use the `plt.subplots()` function for setting up the subplot structure. Use `plt.imshow(x, cmap='gray')` for visualizing a matrix `X` as a grayscale image.  \n",
    "\n",
    "> *Hint:* Use `.reshape()` method for reshaping each array of pixel values into images of shape 16 x 16. \n",
    "\n",
    "**Task 1.5:** Extract the first image and define it as the query vector, i.e. $\\boldsymbol{q} = \\boldsymbol{x}_2$. Make sure that the data matrix $\\boldsymbol{X}$ is updated accordingly.\n",
    "\n",
    "> *Hint:* If in doubt, look up \"NumPy Array Indexing\" and remember that you can stack arrays with `np.vstack()`.\n",
    "\n",
    "> *Hint:* Make sure the query vector is of shape `(1, 256)`. For help, see `.reshape()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d640735b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6fd5ab0fd7da307eca686f09a79f3484",
     "grade": false,
     "grade_id": "cell-4b2e2dc5a9886f52",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Check the shape of the digits dataset\n",
    "assert X.shape == (9297, 16*16), \"There should be 9298 samples and 16x16 = 256 features\"\n",
    "assert q.shape == (1, 16*16), \"There should be 1 sample and 16x16 = 256 features\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74da0994",
   "metadata": {},
   "source": [
    "To measure similarity between $\\boldsymbol{q}$ and the elements in $\\boldsymbol{X}$, we will consider the measures SMC, Jaccard, Cosine, ExtendedJaccard, and Correlation, given by:\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\mathrm{SMC}(\\boldsymbol{q},\\boldsymbol{x}_i)&=\\frac{\\text{Number of matching attribute values}}{\\text{Number of attributes}} = \\frac{\\sum_{j=1}^M \\mathbf{1}\\left[x_{i,j} = q_j\\right]}{M}\\\\ \\\\\n",
    "  \\mathrm{Jaccard}(\\boldsymbol{q},\\boldsymbol{x}_i)&=\\frac{\\text{Number of 11 matching attributes}}{\\text{Number of attributes not involved in 00 matches}} = \\frac{\\sum_{j=1}^M \\mathbf{1}\\left[x_{i,j} = 1, q_{j} = 1\\right]}{M - \\sum_{j=1}^M  \\mathbf{1}\\left[x_{i,j} = 0, q_{j} = 0\\right]  } \n",
    "\\end{align*}\n",
    "$$\n",
    "$$\n",
    "  \\mathrm{Cosine}(\\boldsymbol{q},\\boldsymbol{x}_i) = \\frac{\\boldsymbol{q}^\\top \\boldsymbol{x}_i}{\\|\\boldsymbol{q}\\|\\|\\boldsymbol{x}_i\\|}, \\quad \\qquad\n",
    "  \\mathrm{ExtendedJaccard}(\\boldsymbol{q},\\boldsymbol{x}_i) = \\frac{\\boldsymbol{q}^\\top \\boldsymbol{x}_i}{\\|\\boldsymbol{q}\\|^2+\\|\\boldsymbol{x}_i\\|^2-\\boldsymbol{q}^\\top \\boldsymbol{x}_i}, \\qquad \\quad\n",
    "  \\mathrm{Correlation}(\\boldsymbol{q},\\boldsymbol{x}_i) = \\frac{\\text{cov}(\\boldsymbol{q},\\boldsymbol{x}_i)}{\\text{std}(\\boldsymbol{q})\\text{std}(\\boldsymbol{x}_i)}\n",
    "$$\n",
    "where $\\mathbf{1}\\left[x_{i,j} = q_j\\right]$ denotes the indicator function, $\\displaystyle\\mathrm{cov}(\\boldsymbol{x},\\boldsymbol{y})$ denotes the covariance between $\\boldsymbol{x}$ and $\\boldsymbol{y}$ and $\\text{std}(\\boldsymbol{x})$ denotes the standard deviation of $\\boldsymbol{x}$.\n",
    "\n",
    "The SMC and Jaccard similarity measures are only defined for binary data, i.e., data that takes values of $\\{0,1\\}$. As the\n",
    "data we analyze is non-binary, we will transform the data to be binary when calculating these two measures of similarity by thresholding according to the median per-pixel intensity, i.e. setting\n",
    "$$\n",
    "  x_{i,j}=\\left\\{\\begin{array}{ll} 0 & \\mathrm{if}\\ x_{i, j}<\\mathrm{median}(\\boldsymbol{X}_{:, j}) \\\\\n",
    "    1 & \\mathrm{otherwise}\\end{array} \\right.\n",
    "$$\n",
    "*Note that, depending on the situation, it can be incorrect to encode information in a single binary attribute - and this is true for binary attributes in general. If the meaning behind the value 0 is not specifically non-presence of an attribute, it can be erroneous. For instance, if male/female is encoded in one binary attribute (male: 0, female: 1), some measures will not model the information carried in being male, and a one-of-out-K encoding would be a proper representation.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26621a34",
   "metadata": {},
   "source": [
    "**Task 1.5:** Compute the median per-pixel intensity for the images in $\\boldsymbol{X}$. Binarize the images as $\\boldsymbol{X}_{\\text{binarized}}$ and the query $\\boldsymbol{q}_{\\text{binarized}}$ using the above criteria. Plot the first 5 samples (when including the query).\n",
    "\n",
    "> *Hint:* What should you set the `axis` argument to when using `np.median()`?\n",
    "\n",
    "> *Hint:* You can construct a boolean version using `digits > your_code_here`. Then simply use `.astype(int)` to convert the boolean arrays to binary image arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdedf746",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84752b4ffa7da39950fd1a8c1dabb7b4",
     "grade": false,
     "grade_id": "cell-fcae70709472bcbf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "assert all(np.unique(X_binarized) == [0, 1]), \"X_binarized should be binary...\"\n",
    "assert all(np.unique(q_binarized) == [0, 1]), \"q_binarized should be binary\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5f76a0",
   "metadata": {},
   "source": [
    "**Task 1.6:** Implement at least two of the similarity measures presented above as python functions. Use them to compute the similarity between $\\boldsymbol{q}_{\\text{binarized}}$ and each image in $\\boldsymbol{X}_{\\text{binarized}}$.\n",
    "\n",
    "> *Hint:* The functions `np.sum()`, `np.dot()`, `np.linalg.norm()` and `np.power()` might be useful.\n",
    "\n",
    "> *Hint:* Give it an honest try! But if it's really difficult, check out `sklearn.metrics.pairwise.cosine_similarity`, `sklearn.metrics.jaccard_score` or `scipy.stats.pearsonr`.\n",
    "\n",
    "\n",
    "We provide code for visualizing the most similar images to the query, $\\boldsymbol{q}$, that will run once you implement some of the similarity measures. \n",
    "\n",
    "**Task 1.7:** Read your way through the code for plotting the results. You have to write a line to get `most_similar_order` that should contain the indexes from $[1, 2, \\dots N]$ sorted according to the similarity measure in descending order.\n",
    "\n",
    "> *Hint:* Check out `np.argsort()` for getting the indices in sorted order. Is it sorted in ascending or descending order?\n",
    "\n",
    "> *Hint:* You can reverse the elements of an array by using `x[::-1]`. Hence if `x = [1, 2, 3]`, then `x[::-1]` is `[3, 2, 1]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50d6c45",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "002d126c5aa8f9942c5f234524bd2d76",
     "grade": false,
     "grade_id": "cell-ba6670c937610592",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def smc(q, X):\n",
    "    # q: the binarized query vector of shape (1 x M)\n",
    "    # X: a set of binarized database vectors of shape (N x M)\n",
    "    M = X.shape[1]\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def jaccard(q, X): # or alternatively using sklearn.metrics.jaccard_score\n",
    "    # q: the binarized query vector of shape (1 x M)\n",
    "    # X: a set of binarized database vectors of shape (N x M)\n",
    "    M = X.shape[1]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def cosine(q, X):\n",
    "    # q: the query vector of shape (1 x M)\n",
    "    # X: a set of database vectors of shape (N x M)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def extended_jaccard(q, X):\n",
    "    # q: the query vector of shape (1 x M)\n",
    "    # X: a set of database vectors of shape (N x M)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def correlation(q, X):\n",
    "    # q: the query vector of shape (1 x M)\n",
    "    # X: a set of database vectors of shape (N x M)\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Define the number of top results to retrieve\n",
    "top_k = 5\n",
    "\n",
    "# Define similarity functions to run in a list\n",
    "similarity_functions = [smc, jaccard, cosine, extended_jaccard, correlation]\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(3*top_k, 3*(len(similarity_functions)+1)))\n",
    "# Plot the query image\n",
    "ax = fig.add_subplot(len(similarity_functions)+1, 1, 1)\n",
    "ax.imshow(q_binarized.reshape(16, 16), cmap='gray')\n",
    "ax.set_title(r'$\\boldsymbol{q}$')\n",
    "ax.grid(False)\n",
    "plot_idx = top_k + 1 # update plot index\n",
    "\n",
    "# Iterate over the similarity functions and compute similarities\n",
    "for sim_func in similarity_functions:\n",
    "    # Compute similarities using the binarized images and query\n",
    "    similarities = sim_func(q_binarized, X_binarized)\n",
    "\n",
    "    # Sort indices by similarity in descending order.\n",
    "    # Make sure to construct it as the 1D array `most_similar_order`\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Sort the images in the database\n",
    "    sorted_images = X[most_similar_order]\n",
    "\n",
    "    # Plot the top-k most similar images under the corresponding similarity function\n",
    "    for k in range(top_k):\n",
    "        # Create subplot for each image\n",
    "        ax = fig.add_subplot(len(similarity_functions)+1, top_k, plot_idx)\n",
    "        # Plot the image\n",
    "        ax.imshow(sorted_images[k].reshape(16, 16), cmap='gray')\n",
    "        # Set a title\n",
    "        ax.set_title(f'image #{most_similar_order[k]}\\nSimilarity: {similarities[most_similar_order[k]]:.2f}')\n",
    "        ax.grid(False)\n",
    "\n",
    "        # Add y-label if it's the first image in the row\n",
    "        if k == 0:\n",
    "            ax.set_ylabel(f'{sim_func.__name__.capitalize().replace(\"_\", \" \")}')\n",
    "\n",
    "        # Update plot index\n",
    "        plot_idx += 1\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312813e",
   "metadata": {},
   "source": [
    "Congratulations! If your implementation is correct, we should be able to retrieve somewhat reasonable images using either of the measures and we have the basis of a recommender system.\n",
    "\n",
    "**Task 1.8:** Try to change the query image to e.g. $\\boldsymbol{q}=\\boldsymbol{x}_{14}$. Are the retrieved images still related to the query? Argue why / why not?\n",
    "\n",
    "- *Answer:* \n",
    "\n",
    "**Task 1.9:** How does the *least* similar images look? And what happens if you use $\\boldsymbol{X}$ and $\\boldsymbol{q}$ instead of $\\boldsymbol{X}_{\\text{binarized}}$ and $\\boldsymbol{q}_{\\text{binarized}}$ when computing the similarities?\n",
    "\n",
    "- *Answer:* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d413e1d6",
   "metadata": {},
   "source": [
    "We will now investigate how scaling and translation impact the following three similarity measures: Cosine, ExtendedJaccard, and Correlation. \n",
    "\n",
    "**Task 1.10:** Let $\\alpha$ and $\\beta$ be two constants. Determine which of the following statements are correct (you may need to use pen and paper). You can verify your statements with a coding example.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "  \\mathrm{Cosine}(\\boldsymbol{x},\\boldsymbol{y})&=\\mathrm{Cosine}(\\alpha\\boldsymbol{x},\\boldsymbol{y}) \\\\\n",
    "  \\mathrm{ExtendedJaccard}(\\boldsymbol{x},\\boldsymbol{y})&=\\mathrm{ExtendedJaccard}(\\alpha\\boldsymbol{x},\\boldsymbol{y}) \\\\\n",
    "  \\mathrm{Correlation}(\\boldsymbol{x},\\boldsymbol{y})&=\\mathrm{Correlation}(\\alpha\\boldsymbol{x},\\boldsymbol{y}) \\\\\n",
    "  \\mathrm{Cosine}(\\boldsymbol{x},\\boldsymbol{y})&=\\mathrm{Cosine}(\\beta+\\boldsymbol{x},\\boldsymbol{y}) \\\\\n",
    "  \\mathrm{ExtendedJaccard}(\\boldsymbol{x},\\boldsymbol{y})&=\\mathrm{ExtendedJaccard}(\\beta+\\boldsymbol{x},\\boldsymbol{y}) \\\\\n",
    "  \\mathrm{Correlation}(\\boldsymbol{x},\\boldsymbol{y})&=\\mathrm{Correlation}(\\beta+\\boldsymbol{x},\\boldsymbol{y}) \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "> *Hint:* Even though a similarity measure is theoretically invariant e.g. to scaling, it might not be exactly invariant numerically.\n",
    "\n",
    "**Task 1.11:** Discuss the pratical implications of similarity measures that are translation and/or scaling invariant. You can base the discusison on the image digits dataset but think also of non-image example (e.g. retrieving documents based on the bag-of-words representation from last weeks exercise)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bd4b6f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3d9b71957bb299b89e6d57be969b240",
     "grade": false,
     "grade_id": "cell-ad23405ee8844150",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Generate two data objects with M random attributes\n",
    "M = 5\n",
    "x = np.random.rand(1, M)\n",
    "y = np.random.rand(1, M)\n",
    "\n",
    "# Two constants\n",
    "a = 1.5\n",
    "b = 1.5\n",
    "\n",
    "# Check the statements by computing LHS and RHS of the statements\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a26b9b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part 2: Nearest neighbors method in Python\n",
    "\n",
    "In this exercise we will use the $k$-nearest neighbors (KNN) method for classification. First, we will explore how $k$-nearest neighbors work for 4 different synthetic datasets and how the choice of distance/dissimilarity measure used matters, depending on the dataset. We will consider *training* our $k$-nearest neighbors on a *training set* split of the dataset and later evaluate the learned model on a *test set* split of the dataset where we already splitted the datasets for you.\n",
    "\n",
    "**Task 2.1:** Examine the associated datafolder and load the `synth1_train.csv` and `synth1_test.csv` files using Pandas. From the splitted dataset, construct $\\left(\\boldsymbol{X}_{\\text{train}}, \\boldsymbol{y}_{\\text{train}}\\right)$ and $\\left(\\boldsymbol{X}_{\\text{test}},\\boldsymbol{y}_{\\text{test}}\\right)$.\n",
    "\n",
    "> *Hint:* If you forgot how to load `.csv`-files, check last weeks exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43923eb",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a412c9a76697d00bfaa038ce50d9abe1",
     "grade": false,
     "grade_id": "cell-19e450b9976c714d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'synth1'\n",
    "\n",
    "# Load the dataset splits and construct the datamatrices X_train, X_test and target vectors y_train, y_test\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Check that the input shapes are correct\n",
    "assert X_train.shape[1] == 2, f\"Expected 2 features, but got {X_train.shape[1]}\"\n",
    "assert X_test.shape[1] == 2, f\"Expected 2 features, but got {X_test.shape[1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852616d0",
   "metadata": {},
   "source": [
    "Since the data is 2-dimensional, we can examine it closer by making a scatter plot of the points. We make a scatter plot of the points from the training data by directly leveraging Pandas' plotting tools and color the points based on their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the training data, colored by the target variable\n",
    "df_train.plot(kind='scatter', x='x0', y='x1', c='y', cmap='viridis', title=f'Training set: {dataset_name}', figsize=(8, 6), edgecolor='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40699f5",
   "metadata": {},
   "source": [
    "For creating a classification model using $k$-nearest neighbors we need to define what it means to be a close neighbors - or in other words, **how we define similarity between points**. More specifically, we need to choose:\n",
    "- the number of neighbors, $k$\n",
    "- a distance measure, $d(\\boldsymbol{x}_i, \\boldsymbol{x}_j)$\n",
    "\n",
    "We remark that distance measures are inversely related to similarity measures by definition. As an example, we can convert cosine similarity to a distance measure by $1 - \\mathrm{Cosine}(\\boldsymbol{x}_i, \\boldsymbol{x}_j)$ since the maximum cosine similarity is 1.\n",
    "\n",
    "If we want to classify some new observation, $\\boldsymbol{x}^\\ast$, using $k$-nearest neighbors, we then have to:\n",
    "1) compute the distance from $\\boldsymbol{x}^\\ast$ to all points, $\\boldsymbol{x}_i$, from the training data, i.e. $d(\\boldsymbol{x}^\\ast, \\boldsymbol{x}_i)$ where $\\boldsymbol{x}_i$ is the $i$'th row in $\\boldsymbol{X}_{\\text{train}}$.\n",
    "2) find the $k$ nearest data points in $\\boldsymbol{X}_{\\text{train}}$ and get their labels.\n",
    "3) classify $\\boldsymbol{x}^\\ast$ according to the majority label of the $k$ nearest neighbors.\n",
    "\n",
    "As you have seen in the lecture, a common distance measure is the **general Minkowski distance** also known as the **$p$-norm**:\n",
    "$$\n",
    "    d_p\\left(\\boldsymbol{x}^\\ast, \\boldsymbol{x}\\right) = \\left( \\sum_{j=1}^M \\lvert x^\\ast_j - x_{j}\\rvert^p\\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "which reduces to the cityblock (or Manhattan) distance for $p=1$ and the Euclidean distances for $p=2$:\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\text{Cityblock}: \\ d_1\\left(\\boldsymbol{x}^\\ast, \\boldsymbol{x}\\right) = \\sum_{j=1}^M \\lvert x^\\ast_j - x_{j}\\rvert \\qquad \\qquad\n",
    "    \\text{Euclidean}: \\ d_2\\left(\\boldsymbol{x}^\\ast, \\boldsymbol{x}\\right) = \\sqrt{\\sum_{j=1}^M \\lvert x^\\ast_j - x_{j}\\rvert^2}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f73c97",
   "metadata": {},
   "source": [
    "**Task 2.2:** Consider the new observation $\\boldsymbol{x}^\\ast = [1, -1]^\\top$. Use `KNeighborsClassifier` from `sklearn` to classify the point using the Euclidean distance measure and $k=5$.\n",
    "\n",
    "> *Hint:* Checkout the documentation for `sklearn.neighbors.KNeighborsClassifier` to find out how to \"train\" and predict with it.\n",
    "\n",
    "**Task 2.3:** Plot the new observation as a red dot as well as the $k$ closest neighbors as black crosses on top of the training data figure. Verify from the predicted label and visualization that your implementation is correct.\n",
    "\n",
    "> *Hint:* You can find the closest neighbors using the `.kneighbors()` method of the `KNeighborsClassifier` object.\n",
    "\n",
    "> *Hint:* Set `marker='x'` or `marker='o'` in `plt.scatter()` for getting crosses and dots, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20613a3e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da05ed54fceb5287285faf594623fd06",
     "grade": false,
     "grade_id": "cell-279e83d6c4df3c23",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "x_new = np.array([[1, -1]])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Visualize the training data, colored by the target variable\n",
    "df_train.plot(kind='scatter', x='x0', y='x1', c='y', cmap='viridis', title=f'Training set: {dataset_name}', figsize=(8, 6), edgecolor='gray')\n",
    "\n",
    "# Plot the new point and its closest neighbors\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645294b8",
   "metadata": {},
   "source": [
    "We are interested in determining how well this classification method works. To do so, we use it to classify the test dataset $\\boldsymbol{X}_{\\text{test}}$ and compare the predictions with the true test labels $\\boldsymbol{y}_{\\text{test}}$.\n",
    "\n",
    "**Task 2.4:** Compute the predicted labels for all data points in $\\boldsymbol{X}_{\\text{test}}$ and compute the accuracy and error rate. Generate the confusion matrix and plot it. How well does the model perform? Does it perform specifically better/worse on some classes than others?\n",
    "\n",
    "> *Hint:* To generate a confusion matrix, you can use the function `confusion_matrix()` function from the `sklearn.metrics` module. Use `plt.imshow()` for plotting the matrix or `sns.heatmap()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3239bd8",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29d3d94f9fdfb500d06faedc691f0645",
     "grade": false,
     "grade_id": "cell-6278927a1646a194",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e8896",
   "metadata": {},
   "source": [
    "In addition to this, we might be able to say something qualitatively about the model's performance by visualizing the **decision boundary** - that is how the 2D input space is separeted by the $k$-nearest neighbors model.\n",
    "\n",
    "**Task 2.5:** Visualize the decision boundary by predicting the label for every input point $\\boldsymbol{x}^\\ast$ in a fine grid over the input space. Plot the training and test data on top.\n",
    "\n",
    "> *Hint:* The first lines of code generates a fine grid of points in the input space and stacks them into the data matrix format of shape $N \\times M$.\n",
    "\n",
    "> *Hint:* Apply your $k$-nearest neighbors model to every point on the grid and store the labels. Then reshape the predicted labels into shape `resolution` $\\times$ `resolution` and plot the decision boundary using `plt.imshow()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f0df7e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7861d79fc2f6f9e1178f2dc115d284e4",
     "grade": false,
     "grade_id": "cell-1d6b30b3dad3070f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define resolution of the grid, i.e. how many points per axis\n",
    "resolution = 500\n",
    "# Construct the grid\n",
    "min_x0, max_x0 = X_train[:, 0].min() - 0.5, X_train[:, 0].max() + 0.5\n",
    "min_x1, max_x1 = X_train[:, 1].min() - 0.5, X_train[:, 1].max() + 0.5\n",
    "X_pred = np.meshgrid(\n",
    "    np.linspace(min_x0, max_x0, resolution),\n",
    "    np.linspace(min_x1, max_x1, resolution)\n",
    ")\n",
    "# Stack the grid points into the format of X, i.e. shape N x M\n",
    "X_pred = np.stack([X_pred[0].ravel(), X_pred[1].ravel()]).T\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f91df",
   "metadata": {},
   "source": [
    "**Task 2.6:** Go back and experiment with the distance measure and number of neighbors and run the experiment for the other synthetic datasets too. As distance measures, consider cityblock, Euclidean and cosine as discussed in Part 1 (specifically useful for the `synth2` dataset). Which distance measures worked best for the four problems? Can you explain why? How many neighbors were needed for the four problems? Can you give an example of when it would be good to use a large/small number of neighbors? Consider e.g. when clusters are well separated versus when they are overlapping.\n",
    "\n",
    "- *Answer:* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6caea58",
   "metadata": {},
   "source": [
    "### Regression with $k$-nearest neighbors\n",
    "\n",
    "In the previous example we used $k$-nearest neighbors for solving a classification problem, but the method can just as well be used for modeling a regression task. We follow a similar algorithmic approach as before when predicting the regression output of a new observation, $\\boldsymbol{x}^\\ast$, that is:\n",
    "1) compute the distance from $\\boldsymbol{x}^\\ast$ to all points, $\\boldsymbol{x}_i$, from the training data, i.e. $d(\\boldsymbol{x}^\\ast, \\boldsymbol{x}_i)$ where $\\boldsymbol{x}_i$ is the $i$'th row in $\\boldsymbol{X}_{\\text{train}}$.\n",
    "2) find the $k$ nearest data points in $\\boldsymbol{X}_{\\text{train}}$ and get the associated target attribute values from $\\boldsymbol{y}_{\\text{train}}$.\n",
    "3) average the associated target attribute values of the $k$ nearest neighbors as the predicted output.\n",
    "\n",
    "We provide a simple example in 1D below for a sinusoidal function with noisy observations in the range $x\\in[0,1]$. First, we compute the prediction of $x^\\ast = 0.5$ and show its $k=5$ nearest neighbors. Next, we compute predictions for a fine grid of points in the range of $x$ and plot the results as our **approximated function**. Read your way through the code and understand the details of this toy experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef788329",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # for reproducibility\n",
    "\n",
    "# Experiment parameters\n",
    "k = 5                       # number of neighbors\n",
    "N = 20                      # number of points\n",
    "observation_noise = 0.25    # standard deviation of observation noise\n",
    "\n",
    "# Define the true (unseen) function\n",
    "def sine_function(x, frequency: int = 5):\n",
    "    return np.sin(frequency * x)\n",
    "\n",
    "# Define a new test point\n",
    "x_new = np.array([[0.5]])\n",
    "\n",
    "# Generate training data\n",
    "X_train = np.random.rand(N, 1) # Sample training data points\n",
    "y_train = sine_function(X_train) + np.random.normal(0, observation_noise, (N, 1)) # Get target values for training points, with observation noise\n",
    "\n",
    "# Compute the steps of k-nearest neighbors\n",
    "# Note that all general Minkowski distances can be computed using the same method in 1D - can you argue why?\n",
    "distances = np.linalg.norm(X_train - x_new, axis=1)\n",
    "most_similar_idxs = np.argsort(distances)[:k]  # Get the indices of the k nearest neighbors\n",
    "y_pred = y_train[most_similar_idxs].mean()  # Predict the output for the new input\n",
    "\n",
    "# Make a subplot layout\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5), sharex=True, sharey=True)\n",
    "\n",
    "# Plot training data\n",
    "axs[0].plot(X_train, y_train, 'o', label='Training data') \n",
    "# Plot the results of kNN for a single point\n",
    "axs[0].vlines(x_new, ymin=y_train.min(), ymax=y_train.max(), color='r', linestyle='--', label=fr'New point, $x^\\ast={x_new.item()}$')\n",
    "# Highlight the nearest neighbors\n",
    "axs[0].plot(X_train[most_similar_idxs], y_train[most_similar_idxs], 'o', color='orange', label=f'$k$={k} nearest neighbors') \n",
    "# Plot the predicted value\n",
    "axs[0].plot(x_new, y_pred, 'ro', mec='k', label=fr'Predicted value, $\\hat{{y}}={y_pred.item():.2f}$') \n",
    "# Plot the true function\n",
    "axs[0].plot(np.linspace(0, 1, 100), sine_function(np.linspace(0, 1, 100)), label='True function', color='k') \n",
    "# Add figure layout elements\n",
    "axs[0].set_title('kNN in 1D (single point example)')\n",
    "axs[0].set_xlabel('x')\n",
    "axs[0].set_ylabel('y')\n",
    "axs[0].legend()\n",
    "\n",
    "\n",
    "# Now we run the same computation but for a fine grid of test points in the interval [0, 1]\n",
    "X_pred = np.linspace(0, 1, 1000).reshape(-1, 1)  # Create a grid of test points\n",
    "distances = np.linalg.norm(X_train[None, :] - X_pred[:, None], axis=2) # vectorized version of computing distances for all test points at once\n",
    "most_similar_idxs = np.argsort(distances, axis=1)[:, :k]  # Get the indices of the k nearest neighbors for each test point\n",
    "y_pred = y_train[most_similar_idxs].mean(axis=1)  # Predict the output for each test point\n",
    "\n",
    "# Plot the results of kNN on the range [0,1]\n",
    "# Plot training data\n",
    "axs[1].plot(X_train, y_train, 'o', label='Training data') \n",
    "# Plot the true function\n",
    "axs[1].plot(np.linspace(0, 1, 100), sine_function(np.linspace(0, 1, 100)), label='True function', color='k') \n",
    "# Plot the predicted function in the range x in [0,1]\n",
    "axs[1].plot(X_pred, y_pred, label='Aprroximated function', color='red') \n",
    "axs[1].set_title(r'Approximated function by kNN, $x^\\ast \\in [0,1]$')\n",
    "axs[1].set_xlabel('x')\n",
    "axs[1].set_ylabel('y')\n",
    "axs[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0978ac5b",
   "metadata": {},
   "source": [
    "**Task 2.7:** Can you explain why the approximated function is a step-wise function? Experiment with the number of neighbors $k$ - what happens if $k=1$ or $k=10$? What happens to the approximate function if you increase the number of samples to $N=200$ in combination with $k=20$? Can you explain what happens to the quality of the fit and why?\n",
    "\n",
    "- *Answer:*\n",
    "\n",
    "In general we can use a concept called **cross-validation** to select the optimal distance metric and number of nearest neighbors $k$ although this can be computationally expensive. We will cover this topic in detail in a later week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d9fe92",
   "metadata": {},
   "source": [
    "## Part 3: Decision trees in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2aa5b7",
   "metadata": {},
   "source": [
    "In the following exericse part, we will study another supervised learning method called **decision trees**. We will first consider how distance-based decision rules can be used to construct a simple tree that separates the input space into different regions. Then, we will consider decision trees and their splitting criteria, which typically rely on measures like Gini impurity, entropy, or variance reduction rather than distances.\n",
    "\n",
    "We will first consider a simple decision tree with two decision rules, that is:\n",
    "$$\n",
    "    A: \\quad \\left \\lVert \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} - \\begin{bmatrix} 0.5 \\\\ 0.5 \\end{bmatrix} \\right \\rVert_2 < 1 \\qquad \\text{and} \\qquad B: \\quad \\left \\lVert \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} - \\begin{bmatrix} -1 \\\\ -1 \\end{bmatrix} \\right \\rVert_1 < 1\n",
    "$$\n",
    "\n",
    "We start by checking condition $A$: if it is true, the point $[x_1, x_2]^\\top$ is classified as class $1$ and if $A$ is false, we move on to check condition $B$. If $B$ is true, the point is also classified as class $1$, otherwise, it is classified as class $0$.\n",
    "\n",
    "**Task 3.1:** Draw this simple decision tree using pen and paper.\n",
    "\n",
    "**Task 3.2:** Generate $N=5000$ samples from the 2-dimensional uniform distribution, i.e. $\\boldsymbol{x} = [x_1, x_2]^\\top \\sim \\mathrm{Uniform}\\left(-2, 2\\right)$. Apply the decision rules according to the structure of the tree. Plot the samples as a scatter plot colored by the class label before and after each decision rule for visualizing how the tree splits the input space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc3394",
   "metadata": {},
   "source": [
    "> *Hint:* Use `np.random.uniform()` to sample from a uniform distribution. Check the documentation for further help.\n",
    "\n",
    "> *Hint:* It might be helpful to define the output of a decision rule as a boolean mask, e.g. `A = np.array([False, True, ..., False])`. Then you can extract points that respect the decision rule as `X[A]`.\n",
    "\n",
    "> *Hint:* A boolean mask can be negated by having `~` in front, i.e. `~A`. This generalizes $\\neg A$ to arrays.\n",
    "\n",
    "> *Hint*: use `np.logical_or()` to get the overlap of two boolean arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc2b430",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "336003c4156d25da89e7768e07ef7630",
     "grade": false,
     "grade_id": "cell-228b29177caf2f72",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "N = 5000\n",
    "M = 2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f28b7",
   "metadata": {},
   "source": [
    "Now that we have established the intuition about decision rules, we will proceed to predictive modeling using decision trees with `sklearn.tree.DecisionTreeClassifier`. As a splitting criterion, the function uses one of the two impurity measures:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\begin{array}{cl}\n",
    "  \\mathrm{gdi}(t)=\\displaystyle 1-\\sum_{i=0}^{c-1}p(i|t)^2\n",
    "  &\\text{equivalent to } \\mathrm{Gini}(t),\\\\\n",
    "  \\mathrm{deviance}(t)=\\displaystyle -2\\sum_{i=0}^{c-1}p(i|t)\\log{p(i|t)}\n",
    "  &\\text{equivalent to } \\mathrm{Entropy}(t).\n",
    "\\end{array}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "We will return to a known example - namely the synthetic datasets from the previous exercise - to see how decision trees quantitatively and qualitatively compare to $k$-nearest neighbors that we considered in the previous exercise.\n",
    "\n",
    "**Task 3.3:** Load the `synth1` dataset again. Fit a decision tree with Gini impurity measure to the training data, compute the accuracy, error rate and confusion matrix for the fitted model. Visualize the decision boundary and the training and test data on top.\n",
    "\n",
    "> *Hint:* type help(tree.DecisionTreeClassifier) to learn how to fit a decision tree in Python.\n",
    "\n",
    "> *Hint:* The parameter `criterion` can be used to choose the splitting criterion (Gini or Entropy).\n",
    "\n",
    "> *Hint:* The parameters `min_samples_split`, `min_samples_leaf`, and `max_depth` influence the stopping criterion.\n",
    "\n",
    "> *Hint:* The parameter `random_state` fixes the pseudo-randomness for ensuring reproducibility when/if re-running the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8edc44",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af95b4a223acf6b6d068fe5dc6ce8f36",
     "grade": false,
     "grade_id": "cell-3c94ac2423d8fc37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'synth1'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "472d6c0e",
   "metadata": {},
   "source": [
    "**Task 3.5:** Go back and experiment with the impurity measure and depth of the decision tree. How does the decision tree classifier compare to the $k$-nearest neighbors classifier? \n",
    "\n",
    "- *Answer:*\n",
    "\n",
    "**Task 3.6:** Run the experiment for the other synthetic datasets too. Which distance measures worked best for the four problems? Can you explain why? How does the decision tree classifier perform compared to the $k$-nearest neighbors classifier? Are there specific settings where one performs better than the other and can you argue why? Consider e.g. how the scale of features impacts the models as well as how well-separated versus overlapping the clusters are.\n",
    "\n",
    "- *Answer:* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee768a",
   "metadata": {},
   "source": [
    "\n",
    "### Classifying vertebrates with decision trees\n",
    "\n",
    "We will now analyze the vertebrate data given in Table 4.1 of the *\"Introduction to Data Mining\"* and fit a decision tree to the data. The vertebrate dataset that contains information about various vertebrate species and their classes. We will try to predict the class label based on the remaining information.\n",
    "\n",
    "**Task 3.7:** Load the vertebrate dataset, `vertebrate.csv`, from the associated data folder and remove the \"Species\" attribute. What are the types of the other attributes?\n",
    "\n",
    "> *Hint:* We remove \"Species\" as it associated a unique species to each observation and therefore is redundant in what we want to model. Use `df.drop()` to do so.\n",
    "\n",
    "**Task 3.8:** Construct the data matrix $\\boldsymbol{X}$ and target vector $\\boldsymbol{y}$ by converting the categories to numerical values. What feature transformation would be meaningful for this data?\n",
    "\n",
    "> *Hint:* You can easily do one-hot-encoding of nominal categorical with `sklearn.preprocessing.OneHotEncoder()`. Check the documentation on how to use it.\n",
    "\n",
    "> *Hint:* Similarly, you can use `sklearn.preprocessing.LabelEncoder()` to encode the target attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482d21a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2efefe04e78d82564ff8262accee2436",
     "grade": false,
     "grade_id": "cell-06ff8ac4f90e0558",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Check the shapes of the resulting arrays\n",
    "assert X.shape == (15, 19), \"There should be 15 samples and 19 features after one-hot encoding\"\n",
    "assert y.shape == (15,), \"There should be 15 labels after encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2fe739",
   "metadata": {},
   "source": [
    "**Task 3.9:** Fit a decision tree to the vertebrates data using the Gini splitting criterion and stop splitting only when nodes are pure. Plot the resulting decision tree. Does it change if you use the `entropy` criterion instead?\n",
    "\n",
    "> *Hint:* Consider how the `min_samples_split` affects growth of the tree. It determines the minimum number of samples required to split an internal node: smaller values allow deeper trees, while larger values limit splitting and result in shallower trees.\n",
    "\n",
    "> *Hint:* Use `sklearn.tree.plot_tree()` to plot the decision tree and consider adding `feature_names=one_hot_encoder.get_feature_names_out()` as an argument. What does the \"value\" represent? \n",
    "\n",
    "**Task 3.10:** From the visualization of the tree, can you interpret what attributes are critical for distinguishing between classes? \n",
    "\n",
    "- *Answer:* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f72bdd9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "750b7fa4575dffa06faf534017a0347d",
     "grade": false,
     "grade_id": "cell-1cc66329d8c81ed8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "criterion = \"gini\"\n",
    "\n",
    "# Fit decision tree classifier, no pruning\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d6d657",
   "metadata": {},
   "source": [
    "**Task 3.11:** Show that a dragon, which is cold-blooded, has scales, gives birth, is semi aquatic, is an aerial creature, has legs, and hibernates, will be classified as a reptile.\n",
    "\n",
    "> *Hint:* Convert `x_new` to a Pandas object, then encode it using your one-hot-encoder.\n",
    "\n",
    "> *Hint:* After predicting the label with your classifier, you can get the string representation using `label_encoder.inverse_transform(y_pred)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78347a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87e451e648fcffc6f460d90b2b49c9b4",
     "grade": false,
     "grade_id": "cell-e9501c33af0a7075",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x_new = {\n",
    "    'Body temperature': 'Cold-blooded',\n",
    "    'Skin cover': 'Scales',\n",
    "    'Gives birth': 'Yes',\n",
    "    'Aquatic creature': 'Semi',\n",
    "    'Aerial creature': 'Yes',\n",
    "    'Has legs': 'Yes',\n",
    "    'Hibernates': 'Yes',\n",
    "}\n",
    "print(f\"New data point: {x_new}\")\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c1c8b2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Part 5: Classification on the Wine data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11093b86",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"display: flex; align-items: flex-start;\">\n",
    "\n",
    "<div style=\"flex: 1; padding-right: 5em;\">\n",
    "\n",
    "We will in this part of the exercise consider two datasets related to red and white variants of the Portuguese \"Vinho Verde\" wine, the data has been downloaded from [this website](http://archive.ics.uci.edu/ml/datasets/Wine+Quality). Only physicochemical and sensory attributes are available, i.e., there is no data about grape types, wine brand, wine selling price, etc. You can see the attributes of the data in the provided table. Attributes 111 are based on physicochemical tests and attribute 12 on human judging. \n",
    "\n",
    "The aim of this exercise is to implement a machine learning pipeline for classifying the color of the wine. We will use visualization and distance measurements to identify outliers and remove these outliers from the data. It might be necessary to remove some outliers before other outlying observations become visible. Thus, the process of finding and removing outliers is often iterative.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"flex: 0 0 350px;\">\n",
    "<table>\n",
    "<thead>\n",
    "<tr>\n",
    "<th>#</th>\n",
    "<th>Attribute</th>\n",
    "<th>Unit</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr><td>1</td><td>Fixed acidity (tartaric)</td><td>g/dm</td></tr>\n",
    "<tr><td>2</td><td>Volatile acidity (acetic)</td><td>g/dm</td></tr>\n",
    "<tr><td>3</td><td>Citric acid</td><td>g/dm</td></tr>\n",
    "<tr><td>4</td><td>Residual sugar</td><td>g/dm</td></tr>\n",
    "<tr><td>5</td><td>Chlorides</td><td>g/dm</td></tr>\n",
    "<tr><td>6</td><td>Free sulfur dioxide</td><td>mg/dm</td></tr>\n",
    "<tr><td>7</td><td>Total sulfur dioxide</td><td>mg/dm</td></tr>\n",
    "<tr><td>8</td><td>Density</td><td>g/cm</td></tr>\n",
    "<tr><td>9</td><td>pH</td><td>pH</td></tr>\n",
    "<tr><td>10</td><td>Sulphates</td><td>g/dm</td></tr>\n",
    "<tr><td>11</td><td>Alcohol</td><td>% vol.</td></tr>\n",
    "<tr><td>12</td><td>Quality score</td><td>010</td></tr>\n",
    "</tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c557f326",
   "metadata": {},
   "source": [
    "**Task 5.1:** Load the wine dataset from the associated data folder. Construct the data matrix $\\boldsymbol{X}$ and the target attribute $\\boldsymbol{y}$ where the target attribute is the wine color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc07451",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "33fb777ad5cd7779000d9334b7da3233",
     "grade": false,
     "grade_id": "cell-0f2a98fd72167e22",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "assert X.shape == (6497, 12), \"There should be 6497 samples and 12 features in the wine dataset\"\n",
    "assert y.shape == (6497,), \"There should be 6497 labels in the wine dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b04b57c",
   "metadata": {},
   "source": [
    "**Task 5.2:** Plot a boxplot of each attribute in $\\boldsymbol{X}$ and compute summary statistics of the data matrix $\\boldsymbol{X}$. What does the mean vs. median for the \"Alcohol\" attribute tell you?\n",
    "\n",
    "> *Hint:* Remember that since `X` is a Pandas dataframe, you can do `X.plot(kind='box')`. \n",
    "\n",
    "> *Hint:* Consider using the Pandas method `.describe()` - it computes several summary statistics at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdef6d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "511e5e771394c7fc02d10c7344968734",
     "grade": false,
     "grade_id": "cell-10c040273a1a9a01",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0a1213",
   "metadata": {},
   "source": [
    "As you can hopefully see from the boxplot and summary statistics, the dataset has many observations that can be considered outliers and in order to carry out analyses later it is important to remove the corrupted observations, e.g. $10^{15}$ is clearly not a proper value for alcohol content! However, it is impossible to see the distribution of the data, because the axis is dominated by these extreme outliers. Say we expect volatide acidity (VA) to be around $0-2 \\textrm{g}/\\textrm{dm}^3$, density (D) to be close to $1 \\textrm{g}/\\textrm{cm}^3$, and alcohol percentage (AP) to be somewhere between $5-20\\% \\textrm{vol}$. We can use this knowledge to define wines with VA $> 2$, D $> 1$ and AP $> 20$ as outliers.\n",
    "\n",
    "**Task 5.3:** Remove outliers from $\\boldsymbol{X}$ according to our expert assumption regarding wine data. Show the boxplot for each attribute after removing these outliers. \n",
    "\n",
    "> *Hint:* Pandas allows for logical conditions like `(df['Alcohol'] > 20)` to identify rows with outliers. Combine multiple conditions using the `|` operator (logical OR), and wrap each condition in parentheses. To remove the outliers, consider using the `~` operator to invert the filter.\n",
    "\n",
    "> *Hint:* You can use the mask to eliminate the outlier observations by e.g. writing `X=X[mask,:]` where `mask` indicates the data objects that should be maintained. Remember also to remove them from the class index vector, `y=y[mask,1]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a18b68",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d9ca43fc880dc60f9f4de2ed05814de",
     "grade": false,
     "grade_id": "cell-1e199a691f2f28aa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "assert X.shape == (6304, 12), \"There should be 6304 samples and 12 features in the wine dataset after outlier removal\"\n",
    "assert y.shape == (6304,), \"There should be 6304 labels in the wine dataset after outlier removal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e89b2d",
   "metadata": {},
   "source": [
    "We will now attempt to classify the type of wine i.e. white or red (and later also the quality score) based on the physicochemical tests. Visual inspection of the data can give an indication of the difficulty of these tasks. In the following code cell, we plot a matrix scatter plot for all attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of attributes\n",
    "M = X.shape[1]  \n",
    "\n",
    "# Plot a matrix scatter plot of the wine attributes, colored by the wine color\n",
    "fig, axs = plt.subplots(M, M, figsize=(20, 20), sharex='col', sharey='row')\n",
    "for i in range(M):\n",
    "    for j in range(M):\n",
    "        for color in y.unique(): # loop through each label\n",
    "            # Construct a mask based on the label\n",
    "            mask = (y == color)\n",
    "            # Plot the scatter plot for attribute pair (if not on the diagonal)\n",
    "            axs[i, j].scatter(\n",
    "                x=X[mask].iloc[:, j],        # x-values for the $j$'th attribute\n",
    "                y=X[mask].iloc[:, i],        # y-values for the $i$'th attribute\n",
    "                label=color, alpha=0.3,\n",
    "                color='r' if color == 'Red' else 'y'\n",
    "            )\n",
    "\n",
    "# Update titles\n",
    "for col in range(M):\n",
    "    axs[0, col].set_title(X.columns[col])\n",
    "    axs[col, 0].set_ylabel(X.columns[col])\n",
    "\n",
    "# Add the legend to the last subplot only\n",
    "axs[0,0].legend(loc='upper left')\n",
    "plt.tight_layout(pad=1.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c658d2b1",
   "metadata": {},
   "source": [
    "**Task 5.5:** Does any of the attributes appear to correlate with each other? Validate your findings by computing the correlation matrix between all attributes and the target attribute. \n",
    "\n",
    "> *Hint:* The easiest way is to construct a modified Pandas dataframe, i.e. `df_tilde`, by concatenating `X_tilde` and `y` using `pd.concat()`.\n",
    "\n",
    "> *Hint:* Make sure to convert `y` to numerical values before computing the correlation. There are several ways but one is to cast `y` to categorical with `y.astype(\"category\")` and get the codes by `y.cat.codes`\n",
    "\n",
    "> *Hint:* Use the Pandas method `.corr()` and `plt.imshow()` to visualize the correlation matrix.\n",
    "\n",
    "**Task 5.6:** Are there any of the physicochemical measurements that seem to be well suited in order to discriminate between red and white wines? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc762de",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "495d8e2572fabb7476c98bb7c7c5c6b0",
     "grade": false,
     "grade_id": "cell-7cf91f02c25c333e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe33e6",
   "metadata": {},
   "source": [
    "There indeed seems to be correlation between the target attribute and some input attributes so we will go ahead and try fitting a decision tree and a $k$-nearest neighbor to the data in $\\tilde{\\boldsymbol{X}}$. We proceed as follows:\n",
    "1) We remove the \"Quality score\" attribute\n",
    "2) We construct a random training and test set split of the data in order to evaluate and compare the two methods\n",
    "3) We standardize the training and test data according to the statistics of the **training data**. We want no information leaking from the training data to the test data as this will bias the model performance - but more on that in a later week!\n",
    "The code for these three steps is provided in the cell below.\n",
    "\n",
    "**Task 5.7:** Fit a decision tree with `min_samples_split=100` and the entropy splitting criterion as well as a $k$-nearest neighbor with $k=5$ and Euclidean distance measure to the training data using `sklearn`. Compute the accuracies, error rates and confusion matrices for the fitted models. Which model seems better qualitatively and quantitatively? What happens if you change the hyperparameters of each method?\n",
    "\n",
    "> *Hint:* Do the two method make the same type of mistakes when you examine their confusion matrices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8229b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f328f2ba24f55dd33185c3f7cc2df621",
     "grade": false,
     "grade_id": "cell-ae6688a88f02413a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Split the data into training and test sets of proportion 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.drop(columns=[\"Quality score (0-10)\"]), y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Compute mean and standard deviation of each attribute of the training dataset\n",
    "mean = X_train.mean(axis=0)\n",
    "std = X_train.std(axis=0)\n",
    "\n",
    "# Standardize the training and test data. This ensures that the models are not biased towards \n",
    "# any particular feature due to differences in scale, which could impact model performance, especially for distance-based algorithms.\n",
    "X_train = (X_train - mean) / std\n",
    "X_test = (X_test - mean) / std\n",
    "\n",
    "# Fit the models to the training data 0and predict on the test set\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9747bbd0",
   "metadata": {},
   "source": [
    "**Task 5.8:** Try to comment out the standardization step. What happens to the model performance? Can you explain why?\n",
    "\n",
    "**Task 5.9:** Show that a wine with the following attribute values would be classified as White by the decision tree and Red by the $k$-nearest neighbor model. Do you have any idea why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee7bd2d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9afc4ad87e8e71c25c946d314bab853",
     "grade": false,
     "grade_id": "cell-bdfd3f86a69be48d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Define a new data object (new type of wine) with the attributes given in the text\n",
    "x_new = pd.DataFrame([[6.9, 1.09, 0.06, 2.1, 0.0061, 12, 31, 0.99, 3.5, 0.44, 12]], columns=X_train.columns)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92751a6",
   "metadata": {},
   "source": [
    "**Task 5.10:** Compute the average red and white wines in the training data and store them in a dataframe. Verify that both method predict these correctly.\n",
    "\n",
    "> *Hint:* Use indexing like `X_train[y_train == \"Red\"]` to get all red wines in the training data.\n",
    "\n",
    "> *Hint:* Remember to revert the standardization procedure, i.e. `average_red * std + mean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c227253a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9362fbc83bca60eaecdf9b26734e3afa",
     "grade": false,
     "grade_id": "cell-746101bee1cf3108",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Display the average wines\n",
    "average_wines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "02450-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
